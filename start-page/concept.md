# ডিপ নিউরাল নেটওয়ার্কের লেয়ারিং কনসেপ্ট

যদিও আমরা এখানে একটা সিঙ্গেল লেয়ার নিয়ে কাজ করছি, তবে ডিপ লার্নিং নেটওয়ার্কে ইনপুট এবং আউটপুট লেয়ারের মধ্যে অনেকগুলো হিডেন লেয়ার থাকতে পারে। যেটাকে আমরা নেটওয়ার্কের ডেপথ বলতে পারি। যত বেশি নোডের লেয়ার এর ভেতর দিয়ে ডাটা পার হবে, ততগুলো প্যাটার্ন রিকগনিশন এর প্রসেস চলতে থাকবে এই হিডেন লেয়ার গুলোতে।

শুরুর দিকের নিউরাল নেটওয়ার্ক গুলো র গভীরতা বেশি ছিল না কারণ এইযে পার্সপ্ট্রন, যেটার মধ্যে একটা ইনপুট আরেকটা আউটপুট লেয়ার, খুব বেশি হলে একটা হিডেন লেয়ার থাকতে পারে এর মধ্যে। আমাদের একটা ধারণা আছে তিনটা লেয়ারের বেশি একটা নেটওয়ার্ক, \(যার মধ্যে ইনপুট এবং আউটপুট লেয়ার সহ\) তাকে আমরা বলতে পারি একটা ডিপ লার্নিং নেটওয়ার্ক। মোদ্দাকথা একটার বেশি হিডেন লেয়ার থাকলেই সেটা ডিপ লার্নিং নেটওয়ার্ক।

একটা ডিপ লার্নিং নেটওয়ার্কে প্রতিটা নোডের একেকটা লেয়ারকে ট্রেইন করে কিছু স্পেসিফিক সেটের ফিচার দিয়ে, যা আসলে আসে আগের লেয়ারের আউটপুট থেকে। ব্যাপারটা এরকম, প্রতিটা লেয়ার একেকটা ফিচার আলাদা করে হ্যান্ডেল করছে। নিউরাল নেটওয়ার্কের একেকটা লেয়ার থেকে যত বেশি সামনের লেয়ারে এগোবো - ততই সে কমপ্লেক্স ফিচারগুলোকে ঠিকমতো আইডেন্টিফাই করতে পারবে। এটা সে করতে পারে যেহেতু সে আগের লেয়ারে নিচের ফিচারগুলোকে একসাথে 'এগ্রিগেট' এবং 'কম্বাইন' করে যোগ করতে পারছে ফিচারগুলোকে। একটা উদাহরণ দেই বরং। 

ধরা যাক একটা ছবি থেকে আপনাকে 'আইডেন্টিফাই' মানে 'ট্যাগ' করতে হবে। আমাদের সেই ছবির প্রথম ইনপুট লেয়ারে পিক্সেল হিসেবে সবকিছুই যাবে। পরের লেয়ারে সে পিক্সেলের ইনটেনসিটি বুঝে সেগুলোকে বিভিন্ন ভাগে ফেলবে। এরপরের লেয়ারে কোন অংশগুলো ছবিতে 'ডিস্টিঙ্কট' মানে একদম অন্যরকম, সেগুলোকে আলাদা করে ফেলবে। এরপরের লেয়ারে ধরুন - চোখের একটা 'কোনা'কে আলাদা করে ফেলবে সে। অথবা নাকের একটা অংশ। এই অংশগুলোকে যখন জোড়া লাগাবে তখন পরের কয়েকটা লেয়ারে একটা পুরো চোখ অথবা নাক সে বুঝতে পারবে। চোখ, নাক, কপাল, চিবুক এইসব ঠিকমত বুঝতে পারলে পরের কয়েকটা লেয়ারে পুরো মুখমণ্ডল সে বুঝতে পারার কথা। 

![&#x99A;&#x9BF;&#x9A4;&#x9CD;&#x9B0;&#x983; &#x995;&#x9BF;&#x9AD;&#x9BE;&#x9AC;&#x9C7; &#x9AC;&#x9BF;&#x9AD;&#x9BF;&#x9A8;&#x9CD;&#x9A8; &#x9B2;&#x9C7;&#x9DF;&#x9BE;&#x9B0;&#x9C7; &#x986;&#x9B2;&#x9BE;&#x9A6;&#x9BE; &#x986;&#x9B2;&#x9BE;&#x9A6;&#x9BE; &#x9AB;&#x9BF;&#x99A;&#x9BE;&#x9B0; &#x98F;&#x995;&#x9CD;&#x9B8;&#x99F;&#x9CD;&#x9B0;&#x9CD;&#x9AF;&#x9BE;&#x995;&#x9CD;&#x99F; &#x9B9;&#x99A;&#x9CD;&#x99B;&#x9C7;](../.gitbook/assets/54.jpg)

বুজতেই পারছেন, শুরুর দিকের লেয়ারগুলোর কাজ সোজা, আস্তে আস্তে যত সামনের দিকে এগুবে - বিশেষ করে আউটপুট লেয়ার পর্যন্ত, ততোই ফিচারগুলো কমপ্লেক্স হতে থাকবে। সে কারণে প্রথম দিকের লেয়ার থেকে পরের দিকের লেয়ারগুলোর যে কোন অবজেক্টকে আইডেন্টিফাই করার ক্ষমতা বেশি। এদিকে যেহেতু আগের লেয়ারগুলো তার ছোট ছোট আইটেম কে জোড়া লাগিয়ে দিয়েছে, সে কারণে পরের লেয়ার গুলোর কাজ বেশ সহজ হয়ে যায়। 

এটাকে আমরা বলি ফিচার হায়ারার্কি। একটা অফিসের নিচের কর্মকর্তার কাজের যত চাপ, তার থেকে উপরের দিকের কর্মকর্তার কাজের চাপ বাড়তেই থাকে। এই হায়ারার্কি ফিচারগুলোর কম্প্লেক্সিটি এবং কাজের অ্যাবসট্রাকশন ভালো বুঝতে পারে উপরের দিকে লেয়ারগুলো। এ কারণেই ডিপ লার্নিং নেটওয়ার্কগুলো বিশাল বড় বড় অনেক ডাইমেনশনের ডাটাসেট নিয়ে হ্যান্ডেল করতে পারে। কোন কোন ডাটাসেটগুলোর মধ্যে বিলিয়ন প্যারামিটার থাকে - যাকে আসলে পার হতে হয় অনেক নন-লিনিয়ার ফাংশন। আমি সামনে নন-লিনিয়ার ফাংশন নিয়ে আলাপ করব।

আমাকে যেহেতু অনেক ডেটা নিয়ে কাজ করতে হয়, সেজন্য বলতে পারি পৃথিবীর অধিকাংশ ডাটাই হচ্ছে 'লেবেল ছাড়া' ডাটা, যাকে আমরা আন-স্ট্রাকচার্ড ডেটা বলি। ডিপ লার্নিং এর এই বিভিন্ন লেয়ারের বিভিন্ন ফিচার 'এক্সট্রাকশন' এর কারণে সে যেকোন ডাটার মধ্যে বিভিন্ন প্যাটার্ন স্ট্রাকচার খুঁজে পায়। আমাদের এই 'আন-স্ট্রাকচার্ড' ডাটার মধ্যে ছবি, ভিডিও, অডিও রেকর্ডিং, ইন্টারনেটের ওয়েবসাইটগুলোর কোটি কোটি টেক্সট, এই সব কিছুর মধ্যে কোন কোনটা সাথে সামঞ্জস্য আর কোন কোনটার মধ্যে ব্যত্যয় আছে সেটা বের করতে পারে বড় সমস্যা ছাড়াই। মানুষের মাথা নিজেই একটা বড় নিউরাল নেটওয়ার্ক, তবুও এই বিলিয়ন বিলিয়ন ডেটার মধ্যে এই ধরনের কাজ করা মানুষের জন্য দুষ্কর।

![&#x99A;&#x9BF;&#x9A4;&#x9CD;&#x9B0;&#x983; &#x995;&#x9BF;&#x9AD;&#x9BE;&#x9AC;&#x9C7; &#x9AA;&#x9BF;&#x995;&#x9CD;&#x9B8;&#x9C7;&#x9B2; &#x9A5;&#x9C7;&#x995;&#x9C7; &#x98F;&#x995;&#x99F;&#x9BE; &#x9AC;&#x9C7;&#x9DC;&#x9BE;&#x9B2;&#x995;&#x9C7; &#x99A;&#x9BF;&#x9A8;&#x9A4;&#x9C7; &#x9AA;&#x9BE;&#x9B0;&#x99B;&#x9C7; &#x9A1;&#x9BF;&#x9AA; &#x9B2;&#x9BE;&#x9B0;&#x9CD;&#x9A8;&#x9BF;&#x982; ](../.gitbook/assets/38.png)

সেই কারণেই একটা ডিপ লার্নিং মডেলকে আপনি যদি কোটি কোটি ছবি ইনপুট হিসেবে পাঠান, তাহলে দেখা যাবে - সে গাড়ির ছবিগুলোকে একদিকে, বিড়ালের ছবি আরেকদিকে, আপনার ছবি একদিকে, রাস্তা, নদীর ছবি একদিকে ফেলে দিয়ে ক্যাটেগরি করে ভাগ করে দেবে। আজকে আমাদের মোবাইল ফোনের যতো স্মার্ট ফটো এ্যালবাম দেখছি, তার পিছনে কাজ করছে এই নিউরাল নেটওয়ার্ক।

সেভাবে আপনি যদি সোশ্যাল মিডিয়াতে কমেন্টস এর কথা বলেন, তাহলে কারা কারা ওই প্রডাক্ট কে এনডোর্স করছে আর কত শতাংশ এই প্রোডাক্ট এর ব্যাপারে রাগারাগি করছে সেটাও বের করা সমস্যা নয়। আমি সেন্টিমেন্ট এনালাইসিস এর কথা বলছি। আপনার কাছে কতগুলো ইমেইল পজেটিভ আর নেগেটিভ সেটা বের করতে পারবে এই ডিপ লার্নিং। একটা কল সেন্টারে কত শতাংশ লোক রাগান্বিত অবস্থায় কথা বলে, তার পাশাপাশি কত শতাংশ লোক সেই কল সেন্টার থেকে সার্ভিস পেয়ে সন্তুষ্ট বের করা যাবে ভয়েস রেকর্ড থেকে। 

আরেকটা কথা বলি। আমরা যে মোবাইল ফোন ব্যবহার করি, সেখান থেকে যদি টাইম সিরিজ ডাটা আমরা ডিপ লার্নিং এনালাইসিস করি তাহলে কিন্তু প্রতিটা মানুষের শারীরিক মানসিক স্বাস্থ্য, তার স্বভাব, সামনে সে কি করতে পারে, সেটার বেশ ভালো ধারণা পাওয়া যায়। একটা গাড়ি থেকে যদি আমরা কনস্ট্যান্ট ডাটা ফীড নেই, তাহলে গাড়ির কোন কোন পার্টস সামনে কাজ করবেনা বা নষ্ট হয়ে যাবে সেটা প্রেডিক্ট করা যাবে আগে থেকে। একটা ডাটা সেন্টারের সামনে কোন কোন হার্ড ড্রাইভ ফেইল করবে, সেটা আগে থেকে প্রেডিক্ট করতে পারলে ডাটা লস হবার সম্ভাবনা কম।

আবারো বলছি ডিপ লার্নিং নেটওয়ার্ক কিন্তু অসাধারণ কাজ করে অটোমেটিক ফিচার এক্সট্রেকশন এ। মানুষের কোন সাহায্য ছাড়াই। এই কাজগুলো আমরা করেছি সাধারণ মেশিন লার্নিং এ। অনেক সময় টাটা সাইন্টিস্টদের এই বড় কাজ করতে বছর লাগতো, বিশেষ করে সেই ডোমেইনের এক্সপার্টিজ নেবার ক্ষেত্রে, সেখানে সেই ডোমেইন নলেজ ছাড়াই এই জিনিসটা করা যাচ্ছে সহজে ডিপ লার্নিং দিয়ে। এর সহজ ইন্টারপ্রিটেশন হচ্ছে, আপনি একটা ছোট ডাটা সাইন্স টিম চালাতে পারবেন এই ডিপ লার্নিং এর সাহায্য নিয়ে।

যখন আমরা লেভেল ছাড়া ডাটাকে ট্রেনিং করাই তখন ডিপ নেটওয়ার্কের প্রতিটা নোটের লেয়ার ফিচারগুলো কে শিখতে থাকে স্বয়ংক্রিয়ভাবে - কারণ সে আসলে ইনপুট ডেটাকে আবারো রিকনস্ট্রা ক্ট বা নতুনভাবে তৈরি করতে চায় যাতে তার শুরুর নেটওয়ার্ক যেই ধারণা করে এর পাশাপাশি তার প্রবাবিলিটি দিস্ট্রিবিউশন সেই সাথে মেলানোর চেষ্টা করে। এই প্রসেসে নিউরাল নেটওয়ার্ক গুলো দরকারি ফিচার গুলোর মধ্যে কোরিলেশন খুঁজে বের করে। এর ফলে একটা ভালো আউটপুট এর জন্য ফিচার আউটপুট আর যে ফিচার গুলো এখনো আছে, এদের মধ্যে একটা ভালো সংযোগ খোঁজার চেষ্টা করে। এর ফলে সেটা মডেলের একটা পুরোপুরি নতুন করে রিকনস্ট্রাকশন অথবা লেভেল সহ ডেটা আছে তারমধ্যে দূরত্ব কমিয়ে নিয়ে আসে।

একবার যদি ডিপ লার্নিং নেটওয়ার্কে প্রিন্ট করা হয় লেভেল সহ ডাটার ওপর, তাহলে সেটাকে ব্যবহার করা যাবে নতুন অন স্ট্রাকচার উপর। আমাদের যদি মডেলের ভালো পারফরম্যান্স দরকার হয় তাহলে যত বেশি ডাটার ওপর নিউরাল নেটওয়ার্ক কে ট্রেইন করা যাবে তত বেশি মডেলের দক্ষতা বা অ্যাকুরেসি বাড়বে। এমনও গেছে বাজে অ্যালগরিদম দিয়ে অনেক ডাটার ওপর ট্রেন করালে সেটা হ্য়ালো এলগরিদম যা কম ডাটার ওপর ট্রেন করা হয়েছে তার থেকে ভালো কাজ করে। ডিপ লার্নিং এর ক্ষমতা মানে যত বেশি লেভেল ছাড়া ডাটা দেয়া যাবে সেখানে সে অন্য যেকোনো অ্যালগরিদম থেকে ভালো কাজ করবে।

সবশেষে ডিপ লার্নিং নেটওয়ার্কগুলো কিন্তু তার শেষ আউটকাম দেয় আউটপুট লেয়ারে। এখানে আমরা একটা লজিস্টিক অথবা সফটম্যাক্স বাজে কোন ক্লাসে ফায়ার যা আসলে অন্যান্য আউটপুটের ভেতরে একটা ভোটিংয়ের মাধ্যমে আউটকাম বের করে দেয়। এই আউটপুট লেয়ারে একটা অ্যাক্টিভেশন ফাংশন দিয়ে নন লিনিয়ার এটা থেকে তার প্রেডিকশন তৈরি করে। এর অর্থ হচ্ছে পেছনের ডাটা থেকে শিখে সে একটা ভবিষ্যদ্বাণী করতে পারে। 




# নিউরাল নেটওয়ার্কের কনসেপ্ট এবং রিপ্রেজেন্টেশন লার্নিং

শুরুতেই ডিপ লার্নিং নেটওয়ার্ক হচ্ছে 'কনসেপ্ট হেভি, কোড লাইট'। মানে, আপনি পুরো জিনিসটা মাথায় ধরতে পারলে অল্প কোডেই পার করা যাবে এর আউটকাম। আমাদেরকে বুঝতে হবে কি করতে চাচ্ছি আমরা। আর সেটার আউটকাম। স্টিভেন কোভি'র 'বিগিন উইথ এন্ড ইন মাইন্ড'। 

মনে আছে মেশিন লার্নিং এর কথা? মেশিন লার্নিং এর একটা বড় অংশ জুড়ে আছে ‘ডিসিশন ট্রি’। আগের মেশিন লার্নিং বইটি দেখুন। ‘ডিসিশন ট্রি’ এর মজার ব্যাপার হচ্ছে আপনি রুট নোড থেকে শুরু করে প্রতিটা পরের নোডগুলোতে প্রশ্ন করছেন, কোনটা কি হবে? আপনি যেই ইনপুট ডেটা দিচ্ছেন সেটাকেই সে ক্লাসিফাই করছে তার ট্রেনিং ডেটার রুল অনুযায়ী। আপনি সেই পুরো ডিসিশন ট্রিটাকে প্রিন্ট করে সেখান থেকে রুলগুলো বের করে ফেলতে পারেন। ভুল বললাম?

এর আগে তো আমরা ডাটা হিসেবে ‘টেবুলার ডাটা’, মানে টেবিল আকারের ডাটা দিতাম মেশিন লার্নিং এর মডেলে। আচ্ছা, কেমন হয় যদি আমরা একটা ছবিকে পাঠিয়ে দিই মেশিন লার্নিং মডেলে? ধরুন ডিসিশন ট্রিতে। এখানে ফিচার হিসেবে ডিসিশন ট্রি যা পাবে সেটা হচ্ছে ছবির সবচেয়ে ছোট ইউনিট ‘পিক্সেল’। তার মানে ছবির যেই পিক্সেলগুলোতে সবচেয়ে বেশি ইনফরমেশন আছে সেগুলোকে রুট নোড দিয়ে আলাদা করে ফেলা হবে সেই পিক্সেলের ‘ইনটেনসিটি দিয়ে’। হয়তোবা সে বলবে এই পিক্সেলের \(যদি গ্রে স্কেল হয়\) ইনটেনসিটি ১২৮ এর বেশি হলে ভোটিং ডানে যাবে না হলে বামে যাবে। 

সেভাবে যদি প্রতিটা পিক্সেল, ধরা যাক ইমেজ সাইজ হচ্ছে ১ মেগাপিক্সেল, মানে ১০০০ x ১০০০ x ৩, আমরা ‘কালার আরজিবি’ চ্যানেলের কথা বলছি, লাল, নীল, সবুজ, তার মানে হচ্ছে আমাদের ৩০ লক্ষ ফিচার। এখন এই ছবিকে যদি আমরা এরকম একটা ডিসিশন ট্রির মধ্যে ফেলে দেই, তাহলে তো সেই মডেল তো আর কোনদিন উত্তর নিয়ে ফিরবে না। আর ফিরলেও, আমরা আর থাকবো না। এরপরে যদি আমাদের ফিচার ইঞ্জিনিয়ারিং করতে হয়, তাহলে তো আর কথাই নেই। আমি বলতে চাচ্ছি এক্ষেত্রে মেশিন লার্নিং দক্ষতার পরিচয় দেবে না। 

সে কারণেই চলে এলো ডিপ লার্নিং, যাকে আমরা অনেক সময় বলে থাকি ‘রিপ্রেজেন্টেশন লার্নিং’। আচ্ছা, রিপ্রেজেন্টেশন লার্নিং কি? এ ব্যাপারে এমআইটি’র প্রফেসর প্যাট্রিক উইনষ্টনের একটা চমৎকার ক্লাস লেকচার আছে ইউটিউবে। ধরা যাক, আমাদেরকে একটা কাজ দেওয়া হল কিছু আকারকে ক্লাসিফাই করার জন্য। ছবি দেখুন। আমাদেরকে এমন কিছু ইউনিক বৈশিষ্ট্য বের করতে হবে যাতে আমাদের এই ইনপুট আকারগুলোকে ঠিকমত ক্লাসিফাই করতে পারি। এখানে সেরকম একটা বৈশিষ্ট্য হচ্ছে \(মানে আমাদের মাথার ডিপ লার্নিং বলছে\) এই আকারগুলোর কয়টা ‘কোনা’ আছে তার সংখ্যা জানলেই ক্লাসিফাই করা যাবে আকারগুলোকে। যেমন গোলাকার আকারের কোনা ০, ত্রিভুজের ৩ কোনা, চতুর্ভুজের কোনা সংখ্যা ৪। এখন এই সিস্টেমটা কাজ করার জন্য একটা মডেল তৈরি করি, 

ইনপুট = উপরের এই ছবি

রিপ্রেজেন্টেশন = আকারের কোনা’র সংখ্যা

মডেল = ইনপুটের একটা রিপ্রেজেন্টেশন অথবা ইউনিক ফিচার নিয়ে আসি \(এখানে যেমন কোনা’র সংখ্যা\), এবং সেই রুলগুলোকে অ্যাপ্লাই করি আমাদের আকারগুলোকে ঠিকমতো আইডেন্টিফাই করার জন্য

\(ধরুন, যদি ফিচার ইনপুট = ০ হয় তাহলে সেই আকারটা হবে বৃত্ত\) 

তাহলে বলা যায় যে আমাদের এই মডেলটা চলবে। এই তিন আকারের মধ্যে যাই আসুক না কেন সে সেই আকারটাকে ঠিকমতো ‘আইডেন্টিফাই’ করতে পারবে। কিন্তু এমন যদি হয় তার এখানে অন্যান্য আকার, যেমন ট্রাপিজিয়াম, রম্ভস -- এই তিনটা আকারের বাইরে অন্যান্য যেকোনো জিনিস হলেই কিন্তু এই ফিচার তৈরি করা কষ্টকর হয়ে পড়বে। 

এভাবে ভিন্ন ভিন্ন জিনিস এর জন্য আলাদা আলাদা ফিচার তৈরি করা সময় সাপেক্ষ এবং অনেক ক্ষেত্রে সেটা আর কাজে লাগেনা। আমাদের এমন জিনিস দরকার যে নিজেই ফিচার বের করে নিবে। আর সে কারণেই বলা হচ্ছে এটার জন্য ‘ডিপ ডোমেইন’ জ্ঞান বা এক্সপার্টিজ লাগবে ব্যাপারগুলোকে ঠিকমতো প্রসেস করার জন্য। যাই আসুক না কেন মডেলে সে নিজে থেকে ফিচার বানিয়ে নেবে। 

সে কারণেই এমন একটা মডেল তৈরি করা দরকার যা নিজে থেকেই এই ফিচার গুলোকে তৈরি করতে পারবে, যখন তাকে এধরনের হাজার হাজার ইমেজ দেওয়া হবে। এর আগের ছবিতে আকারগুলোকে দেখে আমাদের মাথা’র ডিপ লার্নিং নেটওয়ার্ক কিন্তু ঠিকই বের করে ফেলেছিল যে ‘কোনা’র সংখ্যাকে ফিচার হিসেবে ধরলে এই আকারগুলোকে ক্লাসিফাই করতে পারবে। আমাদের মস্তিষ্ক যে কাজটা করলো সেটাকে আমরা বলছি ফিচার বা ‘রিপ্রেজেন্টেশন লার্নিং’ অ্যালগরিদম। ডিপ লার্নিং হচ্ছে ওই একই জিনিস।



